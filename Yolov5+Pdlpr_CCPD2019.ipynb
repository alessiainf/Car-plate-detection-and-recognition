{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDWn4NGWWjoi"
      },
      "source": [
        "# Installers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6UhHZODXKZL",
        "outputId": "8f3640dc-f4bc-4826-c6df-2ef22eff80e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tqdm\n",
        "!pip install matplotlib\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --index-url https://download.pytorch.org/whl/cu118 --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1oDSUKGP4Zsx",
        "outputId": "3fb47bdc-4068-4d3a-c152-d7bc32015575"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m682.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.2+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typing-extensions (from torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch==2.0.1+cu118)\n",
            "  Using cached https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy (from torchvision==0.15.2+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from torchvision==0.15.2+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.15.2+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Collecting charset-normalizer<3,>=2 (from requests->torchvision==0.15.2+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchvision==0.15.2+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->torchvision==0.15.2+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17 (from requests->torchvision==0.15.2+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89990 sha256=2c2f28fb9e0c1d1eca609959f044b11f5f5c31e0d74a275eb18f0a1f454324a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\n",
            "Successfully built lit\n",
            "Installing collected packages: mpmath, lit, cmake, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, filelock, charset-normalizer, certifi, requests, jinja2, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.31.6\n",
            "    Uninstalling cmake-3.31.6:\n",
            "      Successfully uninstalled cmake-3.31.6\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.14.1\n",
            "    Uninstalling typing_extensions-4.14.1:\n",
            "      Successfully uninstalled typing_extensions-4.14.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.7.9\n",
            "    Uninstalling certifi-2025.7.9:\n",
            "      Successfully uninstalled certifi-2025.7.9\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu118\n",
            "    Uninstalling torch-2.6.0+cu118:\n",
            "      Successfully uninstalled torch-2.6.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.1 which is incompatible.\n",
            "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.28.1 which is incompatible.\n",
            "curl-cffi 0.11.4 requires certifi>=2024.2.2, but you have certifi 2022.12.7 which is incompatible.\n",
            "typeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.2 which is incompatible.\n",
            "pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 certifi-2022.12.7 charset-normalizer-2.1.1 cmake-3.25.0 filelock-3.13.1 idna-3.4 jinja2-3.1.4 lit-15.0.7 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 pillow-11.0.0 requests-2.28.1 sympy-1.13.3 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0 typing-extensions-4.12.2 urllib3-1.26.13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "numpy"
                ]
              },
              "id": "9d524710dc51403e82713b6e091bf36f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0\" --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "qIqQYS3L5VS-",
        "outputId": "c085b3ac-329b-4265-949c-61ecc45a095a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.2\n",
            "    Uninstalling numpy-2.1.2:\n",
            "      Successfully uninstalled numpy-2.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.28.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "7def2d72eb964680a8c0d119071ada5e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yolov5"
      ],
      "metadata": {
        "id": "7cpJ1Jdl2ydB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60ed3b4-a894-4a6e-a637-c159d282f361"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yolov5\n",
            "  Downloading yolov5-7.0.14-py37.py38.py39.py310-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from yolov5) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from yolov5) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from yolov5) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from yolov5) (11.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from yolov5) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from yolov5) (2.28.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (1.15.3)\n",
            "Collecting thop>=0.1.1 (from yolov5)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from yolov5) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from yolov5) (4.67.1)\n",
            "Collecting ultralytics>=8.0.100 (from yolov5)\n",
            "  Downloading ultralytics-8.3.165-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (2.18.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from yolov5) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from yolov5) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (75.2.0)\n",
            "Collecting fire (from yolov5)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3>=1.19.1 (from yolov5)\n",
            "  Downloading boto3-1.39.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sahi>=0.11.10 (from yolov5)\n",
            "  Downloading sahi-0.11.30-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting huggingface-hub<0.25.0,>=0.12.0 (from yolov5)\n",
            "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting roboflow>=0.2.29 (from yolov5)\n",
            "  Downloading roboflow-1.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting botocore<1.40.0,>=1.39.4 (from boto3>=1.19.1->yolov5)\n",
            "  Downloading botocore-1.39.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.19.1->yolov5)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.19.1->yolov5)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->yolov5) (4.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->yolov5) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->yolov5) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5) (2022.12.7)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.23.0->yolov5)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow>=0.2.29->yolov5)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pillow-heif<2 (from roboflow>=0.2.29->yolov5)\n",
            "  Downloading pillow_heif-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow>=0.2.29->yolov5)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting python-dotenv (from roboflow>=0.2.29->yolov5)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5) (1.17.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5) (1.0.0)\n",
            "Collecting filetype (from roboflow>=0.2.29->yolov5)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sahi>=0.11.10->yolov5) (8.2.1)\n",
            "Collecting pybboxes==0.1.6 (from sahi>=0.11.10->yolov5)\n",
            "  Downloading pybboxes-0.1.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sahi>=0.11.10->yolov5) (2.1.1)\n",
            "Collecting terminaltables (from sahi>=0.11.10->yolov5)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (3.1.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (3.1.4)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.7.0->yolov5) (3.25.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.7.0->yolov5) (15.0.7)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.0.100->yolov5) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.0.100->yolov5)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->yolov5) (3.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->yolov5) (5.0.2)\n",
            "Collecting Pillow>=7.1.2 (from yolov5)\n",
            "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->yolov5) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.7.0->yolov5) (1.3.0)\n",
            "Downloading yolov5-7.0.14-py37.py38.py39.py310-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.5/953.5 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.39.4-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roboflow-1.2.1-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sahi-0.11.30-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading ultralytics-8.3.165-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.39.4-py3-none-any.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading pillow_avif_plugin-1.5.2-cp311-cp311-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=3130c9909cec5c78fb7fdbed27b92554dea8ba87d84f55f9ccdab65e33de5cc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: pillow-avif-plugin, filetype, terminaltables, python-dotenv, pybboxes, Pillow, opencv-python-headless, jmespath, idna, fire, pillow-heif, botocore, sahi, s3transfer, huggingface-hub, roboflow, boto3, ultralytics-thop, ultralytics, thop, yolov5\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.33.2\n",
            "    Uninstalling huggingface-hub-0.33.2:\n",
            "      Successfully uninstalled huggingface-hub-0.33.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.1 which is incompatible.\n",
            "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.28.1 which is incompatible.\n",
            "transformers 4.53.1 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 0.24.7 which is incompatible.\n",
            "diffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.24.7 which is incompatible.\n",
            "peft 0.16.0 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.24.7 which is incompatible.\n",
            "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.24.7 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-11.3.0 boto3-1.39.4 botocore-1.39.4 filetype-1.2.0 fire-0.7.0 huggingface-hub-0.24.7 idna-3.7 jmespath-1.0.1 opencv-python-headless-4.10.0.84 pillow-avif-plugin-1.5.2 pillow-heif-1.0.0 pybboxes-0.1.6 python-dotenv-1.1.1 roboflow-1.2.1 s3transfer-0.13.0 sahi-0.11.30 terminaltables-3.1.10 thop-0.1.1.post2209072238 ultralytics-8.3.165 ultralytics-thop-2.0.14 yolov5-7.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6zHtiEirK1S"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m23XabQWLqP",
        "outputId": "3f9de715-35a6-47a4-e5d9-de6755661e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "#utils\n",
        "import os\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#igfe\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.__version__)\n",
        "\n",
        "import math\n",
        "import random\n",
        "import csv\n",
        "\n",
        "#data\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "import yolov5\n",
        "import torch\n",
        "import os\n",
        "\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore::FutureWarning\"\n",
        "\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmf_AY92rK1T"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q1cKWvixrK1T"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A7rp1lFQrK1U"
      },
      "outputs": [],
      "source": [
        "# Proper license plate decoding\n",
        "def decode_plate(filename):\n",
        "    try:\n",
        "        code = filename.split('-')[4]\n",
        "        indices = list(map(int, code.split('_')))\n",
        "        plate = provinces[indices[0]] + alphabets[indices[1]] + ''.join([ads[i] for i in indices[2:]])\n",
        "        return plate\n",
        "    except:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === FUNZIONI UTILI ===\n",
        "def extract_gt_bbox_from_filename(filename):\n",
        "    try:\n",
        "        bbox_str = filename.split(\"-\")[2]\n",
        "        p1, p2 = bbox_str.split(\"_\")\n",
        "        x1, y1 = map(int, p1.split(\"&\"))\n",
        "        x2, y2 = map(int, p2.split(\"&\"))\n",
        "        return x1, y1, x2, y2\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def compute_iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    boxAArea = max(1, (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n",
        "    boxBArea = max(1, (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n",
        "    return interArea / (boxAArea + boxBArea - interArea + 1e-6)\n",
        "\n",
        "def crop_plate(image, results):\n",
        "    if len(results.pred[0]) == 0:\n",
        "        return None, None\n",
        "    x1, y1, x2, y2 = map(int, results.pred[0][0][:4])\n",
        "    x1, y1 = max(0, x1), max(0, y1)\n",
        "    x2, y2 = min(image.shape[1], x2), min(image.shape[0], y2)\n",
        "    cropped = image[y1:y2, x1:x2]\n",
        "    return cropped, (x1, y1, x2, y2)\n",
        "\n",
        "def preprocess(cropped_img):\n",
        "    img_pil = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))\n",
        "    return val_transforms(img_pil).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "cvKmQT9N3otu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8UCt0SGYrK1U"
      },
      "outputs": [],
      "source": [
        "def ctc_collate_fn(batch):\n",
        "\n",
        "    images, labels = zip(*batch)\n",
        "    images = torch.stack(images, dim=0)  # [B, 3, 48, 144]\n",
        "    targets = torch.cat([torch.tensor(label, dtype=torch.long) for label in labels])\n",
        "    target_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)\n",
        "    input_lengths = torch.full(size=(len(labels),), fill_value=18, dtype=torch.long)\n",
        "\n",
        "    return images, targets, input_lengths, target_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "P8QlsyT3rtOM"
      },
      "outputs": [],
      "source": [
        "# === Decoding CTC ===\n",
        "def ctc_decode(log_probs, idx2char, blank_idx):\n",
        "    preds = log_probs.argmax(2).permute(1, 0)  # [B, T]\n",
        "    decoded = []\n",
        "    for pred in preds:\n",
        "        seq = []\n",
        "        prev = -1\n",
        "        for p in pred:\n",
        "            p = p.item()\n",
        "            if p != blank_idx and p != prev:\n",
        "                seq.append(p)\n",
        "            prev = p\n",
        "        decoded.append(\"\".join([idx2char[i] for i in seq]))\n",
        "    return decoded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWm6rjcQWtai"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EWmC6ps34KEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37671403-74fe-44e1-9612-0829c87fd612"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/Dataset_CV/DETECTION/CCPD2019_detection.zip'\n",
        "extract_path = '/content/CCPD2019_detection'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "Ao7sgQZr3Pm3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEy1ie3HrK1U"
      },
      "source": [
        "Dictionary building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dsdrCU1hWtp7"
      },
      "outputs": [],
      "source": [
        "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\",\n",
        "             \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\",\n",
        "             \"警\", \"学\", \"O\"]\n",
        "\n",
        "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S',\n",
        "             'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'O']\n",
        "\n",
        "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T',\n",
        "       'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
        "\n",
        "base_chars = sorted(set(provinces + alphabets + ads))\n",
        "base_chars.append(\"<BLANK>\")\n",
        "\n",
        "char2idx = {ch: i for i, ch in enumerate(base_chars)}\n",
        "idx2char = {i: ch for ch, i in char2idx.items()}\n",
        "vocab_size = len(base_chars)\n",
        "\n",
        "BLANK_IDX = char2idx[\"<BLANK>\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((48, 144)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "9AHdpU8g8mGA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXuvHg--rK1W"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTlBO0kVYTLd"
      },
      "source": [
        "## IGFE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jt1ueFcYZN0"
      },
      "source": [
        "### Focus structure Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qO8pW6fhYTmL"
      },
      "outputs": [],
      "source": [
        "class FocusStructure(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1):\n",
        "        super(FocusStructure, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels * 4, out_channels, kernel_size, stride, padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # slicing\n",
        "        x1 = x[..., ::2, ::2]\n",
        "        x2 = x[..., ::2, 1::2]\n",
        "        x3 = x[..., 1::2, ::2]\n",
        "        x4 = x[..., 1::2, 1::2]\n",
        "        #concatenation\n",
        "        x = torch.cat([x1, x2, x3, x4], dim=1)\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWueuzt_sQDj"
      },
      "source": [
        "### RESBLOCK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8QyBeT07sPfp"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class RESBLOCK(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(RESBLOCK, self).__init__()\n",
        "        self.cnn1 = CNNBlock(channels, channels)\n",
        "        self.cnn2 = CNNBlock(channels, channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn1(x)\n",
        "        out = self.cnn2(out)\n",
        "        return out + x  # residual connection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDCX5fnfsm_z"
      },
      "source": [
        "### ConvDownSampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nfKbBLTusrxJ"
      },
      "outputs": [],
      "source": [
        "class ConvDownSampling(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvDownSampling, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQPDZ1wms70z"
      },
      "source": [
        "### Feature extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AcljZYJIs7KL"
      },
      "outputs": [],
      "source": [
        "class IGFE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.focus = FocusStructure()            # [3, 48, 144] → [32, 24, 72]\n",
        "        self.res1 = RESBLOCK(32)\n",
        "        self.res2 = RESBLOCK(32)\n",
        "        self.down1 = ConvDownSampling(32, 256)   # [12, 24, 72] → [256, 12, 36]\n",
        "        self.res3 = RESBLOCK(256)\n",
        "        self.res4 = RESBLOCK(256)\n",
        "        self.down2 = ConvDownSampling(256, 512)  # [256, 12, 36] → [512, 6, 18]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.focus(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        x = self.down1(x)\n",
        "        x = self.res3(x)\n",
        "        x = self.res4(x)\n",
        "        x = self.down2(x)\n",
        "        return x  # Final output: [B, 512, 6, 18]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rcvhS5M2xvOe",
        "outputId": "93690de0-d06b-497c-f9af-d53a29ef77a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import os\\nimport torch\\nimport cv2\\nimport matplotlib.pyplot as plt\\nfrom torchvision import transforms\\n\\n# Carica modello IGFE\\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\\nigfe = IGFE().to(device)\\nigfe.eval()\\n\\n# Percorso all\\'immagine singola\\n\\n\\nimg_dir = \"/content/drive/MyDrive/Computer_vision/cropped_plates_48x144/train\"\\nimage_names = sorted(os.listdir(img_dir))  # Assicurati che sia ordinato\\nimg_name = image_names[0]  # Solo la prima\\n\\nimg_path = os.path.join(img_dir, img_name)\\n\\n# Caricamento immagine\\nimg = cv2.imread(img_path)\\nif img is None:\\n    raise FileNotFoundError(f\"Immagine non trovata: {img_path}\")\\n\\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n\\n# Preprocessing: ToTensor + batch dimension\\ntransform = transforms.ToTensor()\\nimg_tensor = transform(img_rgb).unsqueeze(0).to(device)\\n\\n# Passaggio a IGFE\\nwith torch.no_grad():\\n    out = igfe(img_tensor)\\n\\n\\n# Output\\nprint(f\"\\nImage: {img_name}\")\\nprint(f\"Input shape: {img_tensor.shape}\")\\nprint(f\"Output shape IGFE: {out.shape}\")\\n\\n# Visualizza il primo canale del feature map\\nplt.figure(figsize=(5, 3))\\nplt.imshow(out[0, 0].detach().cpu().numpy(), cmap=\"gray\")\\nplt.title(f\"IGFE Output - {img_name}\")\\nplt.axis(\"off\")\\nplt.tight_layout()\\nplt.show()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "'''import os\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "\n",
        "# Carica modello IGFE\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "igfe = IGFE().to(device)\n",
        "igfe.eval()\n",
        "\n",
        "# Percorso all'immagine singola\n",
        "\n",
        "\n",
        "img_dir = \"/content/drive/MyDrive/Computer_vision/cropped_plates_48x144/train\"\n",
        "image_names = sorted(os.listdir(img_dir))  # Assicurati che sia ordinato\n",
        "img_name = image_names[0]  # Solo la prima\n",
        "\n",
        "img_path = os.path.join(img_dir, img_name)\n",
        "\n",
        "# Caricamento immagine\n",
        "img = cv2.imread(img_path)\n",
        "if img is None:\n",
        "    raise FileNotFoundError(f\"Immagine non trovata: {img_path}\")\n",
        "\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Preprocessing: ToTensor + batch dimension\n",
        "transform = transforms.ToTensor()\n",
        "img_tensor = transform(img_rgb).unsqueeze(0).to(device)\n",
        "\n",
        "# Passaggio a IGFE\n",
        "with torch.no_grad():\n",
        "    out = igfe(img_tensor)\n",
        "\n",
        "\n",
        "# Output\n",
        "print(f\"\\nImage: {img_name}\")\n",
        "print(f\"Input shape: {img_tensor.shape}\")\n",
        "print(f\"Output shape IGFE: {out.shape}\")\n",
        "\n",
        "# Visualizza il primo canale del feature map\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.imshow(out[0, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "plt.title(f\"IGFE Output - {img_name}\")\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QOdeP6Mt89m"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaD0Sypn6Tmn"
      },
      "source": [
        "Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OVKF7C6_6VSu"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, height, width):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "        if d_model % 4 != 0:\n",
        "            raise ValueError(\"d_model must be divisible by 4 for 2D positional encoding\")\n",
        "\n",
        "        pe = torch.zeros(d_model, height, width)\n",
        "        d_model_half = d_model // 2\n",
        "        div_term = torch.exp(torch.arange(0, d_model_half, 2).float() * (-math.log(10000.0) / d_model_half))\n",
        "\n",
        "        pos_w = torch.arange(0, width).unsqueeze(1)\n",
        "        pos_h = torch.arange(0, height).unsqueeze(1)\n",
        "\n",
        "        pe[0:d_model_half:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[1:d_model_half:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[d_model_half::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "        pe[d_model_half + 1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))  # [1, d_model, H, W]\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :, :x.size(2), :x.size(3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UZR3WtY-xNTP"
      },
      "outputs": [],
      "source": [
        "class EncoderUnit(nn.Module):\n",
        "    def __init__(self, d_model=512, d_mha=1024, n_heads=8, height=6, width=18):\n",
        "        super(EncoderUnit, self).__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.d_mha = d_mha\n",
        "\n",
        "        self.conv1 = nn.Conv2d(d_model, d_mha, kernel_size=1)\n",
        "        self.mha = nn.MultiheadAttention(d_mha, n_heads, batch_first=True)\n",
        "        self.conv2 = nn.Conv2d(d_mha, d_model, kernel_size=1)\n",
        "        self.norm = nn.LayerNorm(d_model)  # **LayerNorm**\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        # Conv1 → [B, 1024, 6, 18]\n",
        "        x1 = self.conv1(x)\n",
        "\n",
        "        # Flatten per MHA → [B, 108, 1024]\n",
        "        x1_seq = x1.view(B, self.d_mha, H * W).permute(0, 2, 1)\n",
        "\n",
        "        # Multi-Head Attention\n",
        "        attn_out, _ = self.mha(x1_seq, x1_seq, x1_seq)  # [B, 108, 1024]\n",
        "\n",
        "        # Reshape a feature map and CNN BLOCK 2\n",
        "        attn_out = attn_out.permute(0, 2, 1).view(B, self.d_mha, H, W)\n",
        "        x2 = self.conv2(attn_out)  # [B, 512, 6, 18]\n",
        "\n",
        "        # Residual + LayerNorm **(token-wise)**\n",
        "        # Flatten of x e x2 → [B, 108, 512]\n",
        "        x2_seq = x2.view(B, C, H * W).permute(0, 2, 1)\n",
        "        x_res_seq = x.view(B, C, H * W).permute(0, 2, 1)\n",
        "\n",
        "        norm_out = self.norm(x2_seq + x_res_seq)\n",
        "\n",
        "        # Return to the previous dimensions [B, 512, 6, 18]\n",
        "        out = norm_out.permute(0, 2, 1).view(B, C, H, W)\n",
        "        return out\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model=512, d_mha=1024, n_heads=8, num_units=3, height=6, width=18):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.pe2d = PositionalEncoding(d_model, height, width)\n",
        "        self.encoder_units = nn.ModuleList([\n",
        "            EncoderUnit(d_model=d_model, d_mha=d_mha, n_heads=n_heads, height=height, width=width)\n",
        "            for _ in range(num_units)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 512, 6, 18]\n",
        "        x = self.pe2d(x)\n",
        "        for unit in self.encoder_units:\n",
        "            x = unit(x)\n",
        "        return x  # [B, 512, 6, 18]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIW6a_5r_Lml"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Hz6Kj-KZHrwl"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding1D(nn.Module):\n",
        "    def __init__(self, d_model, max_len=18):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
        "\n",
        "    def forward(self, x):  # x: [B, T, D]\n",
        "        if x.size(1) > self.pe.size(1):\n",
        "            raise ValueError(f\"Sequence length {x.size(1)} exceeds max_len={self.pe.size(1)} in PositionalEncoding1D.\")\n",
        "        return x + self.pe[:, :x.size(1)].to(x.device)\n",
        "\n",
        "# === Masked Self-Attention ===\n",
        "class MaskedMultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, _ = x.shape\n",
        "        mask = torch.triu(torch.ones(T, T) * float('-inf'), diagonal=1).to(x.device)\n",
        "        attn_output, _ = self.attn(x, x, x, attn_mask=mask)\n",
        "        return self.norm(x + attn_output)\n",
        "\n",
        "\n",
        "# === Cross-Attention ===\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        attn_output, _ = self.attn(x, context, context)\n",
        "        return self.norm(x + attn_output)\n",
        "\n",
        "\n",
        "# === Feed Forward Network ===\n",
        "class FeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, embed_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embed_dim, embed_dim)\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.norm(x + self.ff(x))\n",
        "\n",
        "\n",
        "# === Decoder Layer: masked self-attn → cross-attn → FFN ===\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim=512, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.self_attn = MaskedMultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.cross_attn = CrossAttention(embed_dim, num_heads)\n",
        "        self.ffn = FeedForwardNetwork(embed_dim)\n",
        "\n",
        "    def forward(self, x, encoder_out):\n",
        "        x = self.self_attn(x)\n",
        "        x = self.cross_attn(x, encoder_out)\n",
        "        x = self.ffn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# CNN BLOCK3 (2x1 kernel, stride=(3,1), padding=1)\n",
        "class CNNBlock3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(512, 512, kernel_size=(2, 1), stride=(3, 1), padding=(1,0))\n",
        "        self.norm = nn.BatchNorm2d(512)\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.norm(self.conv(x)))  # [B, 512, 3, 18] → approx\n",
        "\n",
        "# CNN BLOCK4 (1x1 kernel, stride=(3,1), padding=(0,1))\n",
        "class CNNBlock4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(512, 512, kernel_size=1, stride=(3, 1), padding=(0, 0))\n",
        "        self.norm = nn.BatchNorm2d(512)\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.norm(self.conv(x)))  # [B, 512, 1, 18]\n",
        "\n",
        "\n",
        "\n",
        "# === Final Parallel Decoder (CTC) ===\n",
        "class ParallelTransformerDecoder(nn.Module):\n",
        "    def __init__(self, num_classes, embed_dim=512, num_heads=8, num_layers=3, max_seq_len=18):\n",
        "        super().__init__()\n",
        "        self.block3 = CNNBlock3()\n",
        "        self.block4 = CNNBlock4()\n",
        "        self.pos_encoder = PositionalEncoding1D(embed_dim, max_len=max_seq_len)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(embed_dim, num_heads) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.output_layer = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, encoder_out):  # encoder_out: [B, 512, 6, 18]\n",
        "        x = self.block3(encoder_out)\n",
        "        x = self.block4(x)\n",
        "        x = x.squeeze(2).permute(0, 2, 1)\n",
        "        x = self.pos_encoder(x)\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer(x, x)\n",
        "        logits = self.output_layer(x)\n",
        "        return logits\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "ZD0xmMJK2qC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "# === Full License Plate Recognizer ===\n",
        "class LicensePlateRecognizer(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.igfe = IGFE()  # Output: [B, 128, 6, 18]\n",
        "        self.encoder = Encoder(d_model=512, d_mha=1024, n_heads=8, num_units=3, height=6, width=18)  # Output: [B, 512, 6, 18]\n",
        "\n",
        "        self.decoder = ParallelTransformerDecoder(\n",
        "            num_classes=vocab_size,\n",
        "            embed_dim=512,\n",
        "            num_heads=8,\n",
        "            num_layers=3,\n",
        "            max_seq_len=18\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "        features = self.igfe(image)             # (B, 128, 6, 18)\n",
        "        encoded = self.encoder(features)        # (B, 512, 6, 18)\n",
        "        logits = self.decoder(encoded)          # (B, T, vocab_size)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "44pLt4Sm3FoC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "img_dir = Path(\"/content/CCPD2019_detection/CCPD2019_detection/images/test\")\n",
        "weights_yolo = \"/content/drive/MyDrive/Computer_vision/YoloWeights_finetune/yoloplate_finetuned/weights/best.pt\"\n",
        "weights_pdlpr = \"/content/drive/MyDrive/Computer_vision/pdlpr_weights_ccpd2019/pdlpr_ccpd2019.pth\"\n",
        "\n",
        "yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_yolo)\n",
        "yolo_model.conf = 0.2\n",
        "yolo_model.to(device).eval()\n",
        "\n",
        "model_pdlpr = LicensePlateRecognizer(vocab_size=len(idx2char)).to(device)\n",
        "checkpoint = torch.load(weights_pdlpr, map_location=device)\n",
        "model_pdlpr.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model_pdlpr.eval()"
      ],
      "metadata": {
        "id": "tYzPKqPX3d5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8a331934-8706-4e78-a2c6-d043e647b3ba"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2025-7-12 Python-3.11.13 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LicensePlateRecognizer(\n",
              "  (igfe): IGFE(\n",
              "    (focus): FocusStructure(\n",
              "      (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (res1): RESBLOCK(\n",
              "      (cnn1): CNNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cnn2): CNNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (res2): RESBLOCK(\n",
              "      (cnn1): CNNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cnn2): CNNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (down1): ConvDownSampling(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(32, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (res3): RESBLOCK(\n",
              "      (cnn1): CNNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cnn2): CNNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (res4): RESBLOCK(\n",
              "      (cnn1): CNNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cnn2): CNNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (down2): ConvDownSampling(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (encoder): Encoder(\n",
              "    (pe2d): PositionalEncoding()\n",
              "    (encoder_units): ModuleList(\n",
              "      (0-2): 3 x EncoderUnit(\n",
              "        (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (mha): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "        )\n",
              "        (conv2): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): ParallelTransformerDecoder(\n",
              "    (block3): CNNBlock3(\n",
              "      (conv): Conv2d(512, 512, kernel_size=(2, 1), stride=(3, 1), padding=(1, 0))\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (block4): CNNBlock4(\n",
              "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(3, 1))\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "    (pos_encoder): PositionalEncoding1D()\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn): MaskedMultiHeadSelfAttention(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (cross_attn): CrossAttention(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (ffn): FeedForwardNetwork(\n",
              "          (ff): Sequential(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Dropout(p=0.1, inplace=False)\n",
              "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (output_layer): Linear(in_features=512, out_features=69, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct_seq = 0\n",
        "correct_char = 0\n",
        "total_char = 0\n",
        "total_time = 0.0\n",
        "\n",
        "print(f\"\\nProcessing {img_dir}...\\n\")\n",
        "\n",
        "for img_path in tqdm(sorted(img_dir.rglob(\"*.jpg\"))):\n",
        "    image = cv2.imread(str(img_path))\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    gt_plate = decode_plate(img_path.name)\n",
        "    if gt_plate is None:\n",
        "        continue\n",
        "\n",
        "    gt_box = extract_gt_bbox_from_filename(img_path.name)\n",
        "    if gt_box is None:\n",
        "        continue\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # YOLO detection\n",
        "    results = yolo_model(image)\n",
        "    crop, pred_box = crop_plate(image, results)\n",
        "    if crop is None or crop.size == 0 or pred_box is None:\n",
        "        continue\n",
        "\n",
        "    iou = compute_iou(gt_box, pred_box)\n",
        "    if iou < 0.6:\n",
        "        continue\n",
        "\n",
        "    input_tensor = preprocess(crop)\n",
        "    with torch.no_grad():\n",
        "        logits = model_pdlpr(input_tensor)\n",
        "        log_probs = torch.nn.functional.log_softmax(logits, dim=-1).permute(1, 0, 2)\n",
        "        pred_plate = ctc_decode(log_probs, idx2char, BLANK_IDX)[0]\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    total_time += elapsed\n",
        "\n",
        "\n",
        "    total += 1\n",
        "    if pred_plate == gt_plate:\n",
        "        correct_seq += 1\n",
        "\n",
        "    for p, t in zip(pred_plate, gt_plate):\n",
        "        if p == t:\n",
        "            correct_char += 1\n",
        "    total_char += len(gt_plate)\n",
        "\n",
        "seq_acc = correct_seq / total * 100 if total > 0 else 0\n",
        "char_acc = correct_char / total_char * 100 if total_char > 0 else 0\n",
        "fps = total / total_time if total_time > 0 else 0\n",
        "\n",
        "print(\"\\nFINAL RESULTS:\")\n",
        "print(f\"Sequence Accuracy:  {seq_acc:.2f}%\")\n",
        "print(f\"Character Accuracy: {char_acc:.2f}%\")\n",
        "print(f\"Average FPS:          {fps:.2f} frame/s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_PQNSx36VHq",
        "outputId": "778c6a2e-c9a6-44ae-86b7-7e35e56462c0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing /content/CCPD2019_detection/CCPD2019_detection/images/test...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79999/79999 [25:15<00:00, 52.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL RESULTS:\n",
            "Sequence Accuracy:  89.30%\n",
            "Character Accuracy: 97.70%\n",
            "Average FPS:          52.04 frame/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "img_root_dir = Path(\"/content/CCPD2019_detection/CCPD2019_detection/images/test\")  # root con sottocartelle\n",
        "weights_yolo = \"/content/drive/MyDrive/Computer_vision/YoloWeights_finetune/yoloplate_finetuned/weights/best.pt\"\n",
        "weights_pdlpr = \"/content/drive/MyDrive/Computer_vision/pdlpr_weights_ccpd2019/pdlpr_ccpd2019.pth\"\n",
        "output_csv = \"/content/pdlpr_results_by_folder.csv\"\n",
        "\n",
        "\n",
        "yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_yolo)\n",
        "yolo_model.conf = 0.2\n",
        "yolo_model.to(device).eval()\n",
        "\n",
        "model_pdlpr = LicensePlateRecognizer(vocab_size=len(idx2char)).to(device)\n",
        "checkpoint = torch.load(weights_pdlpr, map_location=device)\n",
        "model_pdlpr.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model_pdlpr.eval()"
      ],
      "metadata": {
        "id": "ildLZPJf31qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for folder in sorted(img_root_dir.iterdir()):\n",
        "    if not folder.is_dir():\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nFolder: {folder.name}\")\n",
        "    total = 0\n",
        "    correct_seq = 0\n",
        "    correct_char = 0\n",
        "    total_char = 0\n",
        "    total_time = 0.0\n",
        "\n",
        "    for img_path in tqdm(sorted(folder.glob(\"*.jpg\"))):\n",
        "        image = cv2.imread(str(img_path))\n",
        "        if image is None:\n",
        "            continue\n",
        "\n",
        "        gt_plate = decode_plate(img_path.name)\n",
        "        if gt_plate is None:\n",
        "            continue\n",
        "\n",
        "        gt_box = extract_gt_bbox_from_filename(img_path.name)\n",
        "        if gt_box is None:\n",
        "            continue\n",
        "\n",
        "        start_time = time.time()\n",
        "        results_yolo = yolo_model(image)\n",
        "        crop, pred_box = crop_plate(image, results_yolo)\n",
        "        if crop is None or crop.size == 0 or pred_box is None:\n",
        "            continue\n",
        "\n",
        "        iou = compute_iou(gt_box, pred_box)\n",
        "        if iou < 0.6:\n",
        "            continue\n",
        "\n",
        "        input_tensor = preprocess(crop)\n",
        "        with torch.no_grad():\n",
        "            logits = model_pdlpr(input_tensor)\n",
        "            log_probs = torch.nn.functional.log_softmax(logits, dim=-1).permute(1, 0, 2)\n",
        "            pred_plate = ctc_decode(log_probs, idx2char, BLANK_IDX)[0]\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        total_time += elapsed\n",
        "\n",
        "        total += 1\n",
        "        if pred_plate == gt_plate:\n",
        "            correct_seq += 1\n",
        "        for p, t in zip(pred_plate, gt_plate):\n",
        "            if p == t:\n",
        "                correct_char += 1\n",
        "        total_char += len(gt_plate)\n",
        "\n",
        "    # Calcolo metriche per questa cartella\n",
        "    seq_acc = correct_seq / total * 100 if total > 0 else 0\n",
        "    char_acc = correct_char / total_char * 100 if total_char > 0 else 0\n",
        "    fps = total / total_time if total_time > 0 else 0\n",
        "\n",
        "    print(f\"→ Sequence Acc: {seq_acc:.2f}% | Char Acc: {char_acc:.2f}% | FPS: {fps:.2f} | N = {total}\")\n",
        "    results.append({\n",
        "        \"folder\": folder.name,\n",
        "        \"images\": total,\n",
        "        \"sequence_accuracy\": seq_acc,\n",
        "        \"character_accuracy\": char_acc,\n",
        "        \"fps\": fps\n",
        "    })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bba75b5-8fc0-41ee-dfdb-b11328ea7877",
        "id": "viznM4_rGrVE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2025-7-11 Python-3.11.13 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Folder: ccpd_base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [03:51<00:00, 43.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Sequence Acc: 99.81% | Char Acc: 99.96% | FPS: 50.07 | N = 9306\n",
            "\n",
            "Folder: ccpd_blur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [02:50<00:00, 58.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Sequence Acc: 67.96% | Char Acc: 91.92% | FPS: 50.53 | N = 4235\n",
            "\n",
            "Folder: ccpd_challenge\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [03:23<00:00, 49.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Sequence Acc: 80.62% | Char Acc: 95.69% | FPS: 50.52 | N = 6889\n",
            "\n",
            "Folder: ccpd_db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [02:57<00:00, 56.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Sequence Acc: 79.61% | Char Acc: 96.01% | FPS: 50.48 | N = 4709\n",
            "\n",
            "Folder: ccpd_fn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [02:57<00:00, 56.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Sequence Acc: 89.63% | Char Acc: 97.92% | FPS: 50.23 | N = 4263\n",
            "\n",
            "Folder: ccpd_rotate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [03:11<00:00, 52.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Sequence Acc: 92.46% | Char Acc: 98.60% | FPS: 49.17 | N = 5279\n",
            "\n",
            "Folder: ccpd_tilt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [03:03<00:00, 54.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Sequence Acc: 88.05% | Char Acc: 97.89% | FPS: 48.53 | N = 4486\n",
            "\n",
            "Folder: ccpd_weather\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9999/9999 [03:46<00:00, 44.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Sequence Acc: 99.36% | Char Acc: 99.89% | FPS: 49.58 | N = 8492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vDWn4NGWWjoi",
        "a6zHtiEirK1S",
        "wmf_AY92rK1T",
        "WWm6rjcQWtai",
        "JXuvHg--rK1W",
        "PTlBO0kVYTLd",
        "8Jt1ueFcYZN0",
        "sWueuzt_sQDj",
        "zDCX5fnfsm_z",
        "wQPDZ1wms70z",
        "_QOdeP6Mt89m",
        "RIW6a_5r_Lml",
        "ZD0xmMJK2qC2"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}